{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"../mmdetection/\")\n",
    "# 이건 본인 환경의 mmdetection 폴더 잡아주면 됨\n",
    "\n",
    "from mmengine.hooks import Hook\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.registry import DATASETS\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmevest71\u001b[0m (\u001b[33mmevest71-boostcamp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key='2a631ea744b03506a1330798e0724d1d917a821f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모듈 등록\n",
    "register_all_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file 경로\n",
    "cfg = Config.fromfile('../mmdetection/configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py')\n",
    "\n",
    "# 데이터셋 경로\n",
    "root='./dataset/'\n",
    "\n",
    "# work_dir 경로 (log랑 체크포인트 저장할 곳)\n",
    "root_work_dir='./work_dirs/faster_rcnn_r50_fpn_1x_wandb_og'\n",
    "\n",
    "# train max epochs 수\n",
    "train_epochs = 10\n",
    "\n",
    "# 체크포인트 최대 몇 개 저장해놓을 건지\n",
    "keep_ckpts = 3\n",
    "\n",
    "# 체크포인트 인터벌 (체크포인트 몇번째마다 저장할 건지)\n",
    "ckpts_interval = 1\n",
    "\n",
    "\n",
    "# --------------------------wandb--------------------------\n",
    "\n",
    "# wandb 프로젝트 이름 (안 바꾸는 걸 추천함, 개인적으로 자기 것만 모아놓고 싶으면 바꿔도 됨)\n",
    "wandb_project_name = 'Project2'\n",
    "\n",
    "\n",
    "# wandb 실험 이름 (이건 자기가 원하는 걸로 변경해야 알아보기 편하겠지요?)\n",
    "wandb_experiment_name = '원하는 이름'\n",
    "\n",
    "\n",
    "# 몇 iter(False로 한 경우)마다 로그를 저장할 건지\n",
    "# wandb에 로깅하는 것 뿐만 아니라 log에도 이 인터벌만큼만 찍히므로 참고해서 입력할 것\n",
    "# 0은 못 받음, 0보다 큰 수로 줘야 함\n",
    "# 숫자를 작게 줄수록 로깅을 자주 함(돌려보고 정하면 됨)\n",
    "log_interval = 200\n",
    "\n",
    "\n",
    "# 모델에 따라 아래 쉘의 num_classes 지정하는 부분이나 몇 부분 더 확인해볼 것 (roi_head 써야 하는지 bbox_head에 바로 줘야 하는지 같은 거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.dataset_type = 'CocoDataset'\n",
    "cfg.data_root = root\n",
    "\n",
    "# Train dataset config 수정\n",
    "cfg.train_dataloader = dict(\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
    "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
    "    dataset=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        data_root=cfg.data_root,\n",
    "        ann_file='train.json',\n",
    "        data_prefix=dict(img=''),\n",
    "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
    "        pipeline=cfg.train_pipeline,\n",
    "        metainfo=dict(classes=classes)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Validation dataset config 수정\n",
    "cfg.val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    drop_last=False,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        data_root=cfg.data_root,\n",
    "        ann_file='test.json',\n",
    "        data_prefix=dict(img=''),\n",
    "        test_mode=True,\n",
    "        pipeline=cfg.test_pipeline,\n",
    "        metainfo=dict(classes=classes)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Test dataset config 수정 (validation과 동일하게 설정)\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# Train, val, test evaluator 설정\n",
    "cfg.train_evaluator = dict(\n",
    "    type='CocoMetric',\n",
    "    ann_file=cfg.data_root + 'train.json',\n",
    "    metric='bbox',\n",
    "    format_only=False\n",
    ")\n",
    "\n",
    "cfg.val_evaluator = dict(\n",
    "    type='CocoMetric',\n",
    "    ann_file=cfg.data_root + 'test.json',\n",
    "    metric='bbox',\n",
    "    format_only=False\n",
    ")\n",
    "\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# 기타 설정\n",
    "cfg.train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=train_epochs, val_interval=1)\n",
    "cfg.val_cfg = dict(type='ValLoop')\n",
    "cfg.test_cfg = dict(type='TestLoop')\n",
    "\n",
    "cfg.env_cfg = dict(\n",
    "    cudnn_benchmark=False,\n",
    "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
    "    dist_cfg=dict(backend='nccl'),\n",
    ")\n",
    "\n",
    "cfg.work_dir = root_work_dir\n",
    "\n",
    "# 모델에 따라 선택하거나 아예 바꿔야 할 수도 있음\n",
    "cfg.model.roi_head.bbox_head.num_classes = 10\n",
    "#cfg.model.bbox_head.num_classes = 10\n",
    "\n",
    "cfg.optim_wrapper.optimizer.lr = 0.02\n",
    "cfg.optim_wrapper.clip_grad = dict(max_norm=35, norm_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook, wandb, log, 시각화 관련 코드\n",
    "\n",
    "# 체크포인트 pth와 로그 저장\n",
    "cfg.default_hooks = dict(\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    checkpoint=dict(type='CheckpointHook', interval=ckpts_interval, max_keep_ckpts=keep_ckpts),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    visualization=dict(type='DetVisualizationHook'),\n",
    "    logger=dict(type='LoggerHook', \n",
    "                log_metric_by_epoch=False,\n",
    "                interval=log_interval,\n",
    "                )\n",
    ")\n",
    "\n",
    "wandb_kwargs = dict(\n",
    "    project=wandb_project_name,\n",
    "    name=wandb_experiment_name,\n",
    ")\n",
    "\n",
    "visualizer = dict(\n",
    "    type='DetLocalVisualizer',\n",
    "    vis_backends=[\n",
    "        dict(type='LocalVisBackend'),\n",
    "        dict(type='WandbVisBackend',\n",
    "             init_kwargs=wandb_kwargs)\n",
    "    ],\n",
    "    name='visualizer'\n",
    ")\n",
    "\n",
    "cfg.visualizer = visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/15 14:00:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1639735043\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.1+cu116\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu116\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.1\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1639735043\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "10/15 14:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = './dataset/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=200, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=10,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=False,\n",
      "                min_pos_iou=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='test.json',\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='./dataset/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='./dataset/test.json',\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='train.json',\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='./dataset/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_evaluator = dict(\n",
      "    ann_file='./dataset/train.json',\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='test.json',\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='./dataset/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='./dataset/test.json',\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(name='og test 3', project='Project2'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/faster_rcnn_r50_fpn_1x_wandb_og'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/kjh/level2-objectdetection-cv-16/work_dirs/faster_rcnn_r50_fpn_1x_wandb_og/20241015_140043/vis_data/wandb/run-20241015_140044-h4b6y87e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mevest71-boostcamp/Project2/runs/h4b6y87e' target=\"_blank\">og test 3</a></strong> to <a href='https://wandb.ai/mevest71-boostcamp/Project2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mevest71-boostcamp/Project2' target=\"_blank\">https://wandb.ai/mevest71-boostcamp/Project2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mevest71-boostcamp/Project2/runs/h4b6y87e' target=\"_blank\">https://wandb.ai/mevest71-boostcamp/Project2/runs/h4b6y87e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/15 14:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "10/15 14:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "10/15 14:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: torchvision://resnet50\n",
      "10/15 14:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
      "10/15 14:01:02 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "10/15 14:01:04 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "10/15 14:01:04 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "10/15 14:01:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /data/ephemeral/home/kjh/level2-objectdetection-cv-16/work_dirs/faster_rcnn_r50_fpn_1x_wandb_og.\n",
      "10/15 14:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 200/1221]  lr: 7.9880e-03  eta: 6:10:51  time: 1.5188  data_time: 0.0081  memory: 4460  grad_norm: 2.3582  loss: 0.7747  loss_rpn_cls: 0.1121  loss_rpn_bbox: 0.0501  loss_cls: 0.3565  acc: 93.1641  loss_bbox: 0.2560\n",
      "10/15 14:11:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 400/1221]  lr: 1.5996e-02  eta: 6:02:13  time: 1.5024  data_time: 0.0084  memory: 4460  grad_norm: 2.1891  loss: 0.7150  loss_rpn_cls: 0.0972  loss_rpn_bbox: 0.0520  loss_cls: 0.3291  acc: 84.5703  loss_bbox: 0.2366\n",
      "10/15 14:16:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 600/1221]  lr: 2.0000e-02  eta: 5:53:19  time: 1.4485  data_time: 0.0079  memory: 4460  grad_norm: 1.6125  loss: 0.6629  loss_rpn_cls: 0.0805  loss_rpn_bbox: 0.0460  loss_cls: 0.3079  acc: 96.5820  loss_bbox: 0.2285\n",
      "10/15 14:21:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 800/1221]  lr: 2.0000e-02  eta: 5:47:22  time: 1.5010  data_time: 0.0079  memory: 4460  grad_norm: 1.7097  loss: 0.7844  loss_rpn_cls: 0.0801  loss_rpn_bbox: 0.0487  loss_cls: 0.3787  acc: 91.1133  loss_bbox: 0.2768\n",
      "10/15 14:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20241015_140043\n",
      "10/15 14:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1000/1221]  lr: 2.0000e-02  eta: 5:41:46  time: 1.5134  data_time: 0.0099  memory: 4460  grad_norm: 1.8851  loss: 0.7370  loss_rpn_cls: 0.0853  loss_rpn_bbox: 0.0509  loss_cls: 0.3538  acc: 88.2324  loss_bbox: 0.2470\n",
      "10/15 14:31:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1200/1221]  lr: 2.0000e-02  eta: 5:36:28  time: 1.4963  data_time: 0.0079  memory: 4460  grad_norm: 1.7683  loss: 0.6549  loss_rpn_cls: 0.0638  loss_rpn_bbox: 0.0442  loss_cls: 0.3104  acc: 87.0117  loss_bbox: 0.2365\n",
      "10/15 14:31:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20241015_140043\n",
      "10/15 14:31:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "10/15 14:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 200/4871]    eta: 0:13:44  time: 0.1684  data_time: 0.0020  memory: 4460  \n",
      "10/15 14:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 400/4871]    eta: 0:12:53  time: 0.1650  data_time: 0.0026  memory: 697  \n",
      "10/15 14:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 600/4871]    eta: 0:12:09  time: 0.1693  data_time: 0.0020  memory: 697  \n",
      "10/15 14:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 800/4871]    eta: 0:11:30  time: 0.1672  data_time: 0.0018  memory: 697  \n",
      "10/15 14:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][1000/4871]    eta: 0:10:55  time: 0.1688  data_time: 0.0020  memory: 697  \n",
      "10/15 14:35:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][1200/4871]    eta: 0:10:20  time: 0.1691  data_time: 0.0019  memory: 697  \n",
      "10/15 14:35:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][1400/4871]    eta: 0:09:44  time: 0.1675  data_time: 0.0018  memory: 697  \n",
      "10/15 14:36:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][1600/4871]    eta: 0:09:09  time: 0.1707  data_time: 0.0019  memory: 697  \n",
      "10/15 14:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][1800/4871]    eta: 0:08:35  time: 0.1676  data_time: 0.0018  memory: 697  \n",
      "10/15 14:37:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][2000/4871]    eta: 0:08:01  time: 0.1670  data_time: 0.0019  memory: 697  \n",
      "10/15 14:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][2200/4871]    eta: 0:07:28  time: 0.1728  data_time: 0.0018  memory: 697  \n",
      "10/15 14:38:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][2400/4871]    eta: 0:06:54  time: 0.1701  data_time: 0.0020  memory: 697  \n",
      "10/15 14:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][2600/4871]    eta: 0:06:21  time: 0.1724  data_time: 0.0019  memory: 697  \n",
      "10/15 14:39:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][2800/4871]    eta: 0:05:47  time: 0.1692  data_time: 0.0018  memory: 697  \n",
      "10/15 14:39:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][3000/4871]    eta: 0:05:12  time: 0.1629  data_time: 0.0022  memory: 697  \n",
      "10/15 14:40:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][3200/4871]    eta: 0:04:37  time: 0.1565  data_time: 0.0019  memory: 697  \n",
      "10/15 14:41:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][3400/4871]    eta: 0:04:03  time: 0.1585  data_time: 0.0021  memory: 697  \n",
      "10/15 14:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][3600/4871]    eta: 0:03:30  time: 0.1560  data_time: 0.0019  memory: 697  \n",
      "10/15 14:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][3800/4871]    eta: 0:02:56  time: 0.1491  data_time: 0.0017  memory: 697  \n",
      "10/15 14:42:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][4000/4871]    eta: 0:02:23  time: 0.1568  data_time: 0.0018  memory: 697  \n",
      "10/15 14:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][4200/4871]    eta: 0:01:49  time: 0.1563  data_time: 0.0022  memory: 697  \n",
      "10/15 14:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][4400/4871]    eta: 0:01:17  time: 0.1522  data_time: 0.0018  memory: 697  \n",
      "10/15 14:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][4600/4871]    eta: 0:00:44  time: 0.1540  data_time: 0.0018  memory: 697  \n",
      "10/15 14:44:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][4800/4871]    eta: 0:00:11  time: 0.1562  data_time: 0.0019  memory: 697  \n",
      "10/15 14:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=1.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=9.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.33s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
      "10/15 14:45:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: -1.000 -1.000 -1.000 -1.000 -1.000 -1.000\n",
      "10/15 14:45:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][4871/4871]    coco/bbox_mAP: -1.0000  coco/bbox_mAP_50: -1.0000  coco/bbox_mAP_75: -1.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: -1.0000  data_time: 0.0020  time: 0.1627\n",
      "10/15 14:50:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 200/1221]  lr: 2.0000e-02  eta: 5:30:36  time: 1.4997  data_time: 0.0082  memory: 4460  grad_norm: 1.7061  loss: 0.6561  loss_rpn_cls: 0.0562  loss_rpn_bbox: 0.0428  loss_cls: 0.3200  acc: 92.8711  loss_bbox: 0.2371\n",
      "10/15 14:55:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 400/1221]  lr: 2.0000e-02  eta: 5:25:21  time: 1.4961  data_time: 0.0077  memory: 4460  grad_norm: 1.8117  loss: 0.6755  loss_rpn_cls: 0.0622  loss_rpn_bbox: 0.0503  loss_cls: 0.3227  acc: 94.4824  loss_bbox: 0.2403\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Runner 생성 및 학습 시작\u001b[39;00m\n\u001b[1;32m      2\u001b[0m runner \u001b[38;5;241m=\u001b[39m Runner\u001b[38;5;241m.\u001b[39mfrom_cfg(cfg)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:1777\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_compile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:96\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mval_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_begin\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:112\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:128\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_idx\u001b[38;5;241m=\u001b[39midx, data_batch\u001b[38;5;241m=\u001b[39mdata_batch)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Enable gradient accumulation mode and avoid unnecessary gradient\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# synchronization during gradient accumulation process.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# outputs should be a dict of loss.\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    133\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[1;32m    134\u001b[0m     data_batch\u001b[38;5;241m=\u001b[39mdata_batch,\n\u001b[1;32m    135\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/model/base_model/base_model.py:116\u001b[0m, in \u001b[0;36mBaseModel.train_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    114\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward(data, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    115\u001b[0m parsed_losses, log_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_losses(losses)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_losses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_vars\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py:201\u001b[0m, in \u001b[0;36mOptimWrapper.update_params\u001b[0;34m(self, loss, step_kwargs, zero_kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Update parameters only if `self._inner_count` is divisible by\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# `self._accumulative_counts` or `self._inner_count` equals to\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# `self._max_counts`\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_update():\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_grad(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mzero_kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/optim/scheduler/param_scheduler.py:115\u001b[0m, in \u001b[0;36m_ParamScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m instance\u001b[38;5;241m.\u001b[39m_global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    114\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py:252\u001b[0m, in \u001b[0;36mOptimWrapper.step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A wrapper of ``Optimizer.step``.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03mProvide unified ``step`` interface compatible with automatic mixed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m        :meth:`torch.optim.Optimizer.step`.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_kwargs:\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clip_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py:298\u001b[0m, in \u001b[0;36mOptimWrapper._clip_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# `torch.nn.utils.clip_grad_value_` will return None.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_hub\u001b[38;5;241m.\u001b[39mupdate_scalar(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m--> 298\u001b[0m                                    \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Runner 생성 및 학습 시작\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
